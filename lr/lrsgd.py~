#!/usr/bin/env python
"""
Implement your own version of logistic regression with stochastic
gradient descent.

Author: <rui zhang>
Email : <rzhang316@gatech.edu>
"""

import collections
import math
class LogisticRegressionSGD:
    def __init__(self, eta, mu, n_feature):
        """
        Initialization of model parameters
        """
        self.eta=float(eta)
	self.mu=float(mu);
        self.weight=[0.0] * n_feature

    def fit(self, X, y):
	print X
	error=y-1.0 /(1.0 + math.exp(-math.fsum((self.weight[f]*v for f, v in X))))
	for f,v in X:
	    self.weight[f]=self.weight[f]+self.eta*error*v-2*self.eta*self.mu*self.weight[f]
    def predict(self, X):
        return 1 if predict_prob(X) > 0.5 else 0;

    def predict_prob(self, X):
        return 1.0 /(1.0 + math.exp(-math.fsum((self.weight[f]*v for f, v in X))))
